{
  "timestamp": "2025-10-02T04:57:48.260Z",
  "range": {
    "start": 5,
    "end": 12
  },
  "metrics": {
    "categories": {
      "terms": {
        "expected": 5,
        "correct": 4,
        "accuracy": 80,
        "found": [
          "AI microscope",
          "features",
          "circuits",
          "language of thought"
        ],
        "missed": [
          "AI biology"
        ],
        "wrong": []
      },
      "concepts": {
        "expected": 2,
        "correct": 0,
        "accuracy": 0,
        "found": [],
        "missed": [
          "This means that we don't understand how models do most of the things they do",
          "So we look inside"
        ],
        "wrong": [
          "they‘re trained on large amounts of data. During that training process, they learn their own strategies to solve problems",
          "This means that we don’t understand how models do most of the things they do",
          "Knowing how models like Claude think would allow us to have a better understanding of their abilities, as well as help us ensure that they’re doing what we intend them to",
          "We take inspiration from the field of neuroscience, which has long studied the messy insides of thinking organisms, and try to build a kind of AI microscope that will let us identify patterns of activity and flows of information",
          "In the first paper, we extend our prior work locating interpretable concepts (\"features\") inside a model to link those concepts together into computational \"circuits\", revealing parts of the pathway that transforms the words that go into Claude into the words that come out",
          "Claude sometimes thinks in a conceptual space that is shared between languages, suggesting it has a kind of universal “language of thought.”"
        ]
      },
      "examples": {
        "expected": 0,
        "correct": 0,
        "accuracy": 0,
        "found": [],
        "missed": [],
        "wrong": [
          "Claude can speak dozens of languages. What language, if any, is it using \"in its head\"",
          "Claude writes text one word at a time. Is it only focusing on predicting the next word or does it ever plan ahead",
          "Claude can write out its reasoning step-by-step. Does this explanation represent the actual steps it took to get to an answer, or is it sometimes fabricating a plausible argument for a foregone conclusion",
          "There are limits to what you can learn just by talking to an AI model—after all, humans (even neuroscientists) don't know all the details of how our own brains work",
          "We show this by translating simple sentences into multiple languages and tracing the overlap in how Claude processes them"
        ]
      }
    },
    "overall": {
      "totalExpected": 7,
      "totalCorrect": 4,
      "accuracy": 57.14
    },
    "charCounts": {
      "byCategory": {
        "terms": {
          "expected": 58,
          "llm": 48,
          "diff": -10,
          "percentDiff": -17.24
        },
        "concepts": {
          "expected": 93,
          "llm": 1008,
          "diff": 915,
          "percentDiff": 983.87
        },
        "examples": {
          "expected": 0,
          "llm": 688,
          "diff": 688,
          "percentDiff": 0
        }
      },
      "total": {
        "expected": 151,
        "llm": 1744,
        "diff": 1593,
        "percentDiff": 1054.97
      }
    }
  }
}